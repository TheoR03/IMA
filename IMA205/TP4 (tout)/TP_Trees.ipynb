{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G8OIJnHSo1_T"
   },
   "source": [
    "# Alzheimer prediction using gray matter density from T1w MRI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vN4bwTpJo1_Z"
   },
   "source": [
    "**Deadline**: Upload this notebook (rename it as 'TP4-IMA205-YOUR-SURNAME.ipynb') with your answers to the Site pédagogique before the 18th of March 2020 (23h59).\n",
    "\n",
    "Please complete the code where you see XXXXXXXXXXXX and answer the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GB1qko7fo1_g"
   },
   "source": [
    "We will use a dataset composed of neuroimaging features from brain T1w MR images of 752 subjects, 416 controls and 336 with Alzheimer’s disease. Following the pipeline described in [1], all images are first normalized to a\n",
    "common space, providing a voxel-wise correspondence across subjects. Then, gray matter density is computed at each voxel and averaged over a set of ROIs (Region of Interest) of an atlas, at the beginning you will use the [AAL2 atlas](http://www.gin.cnrs.fr/en/tools/aal/). Data comes from several freely available datasets, like [ADNI](http://adni.loni.usc.edu/) and [OASIS](https://www.oasis-brains.org/), and has been pre-processed by the [Clinica](http://www.clinica.run/) team using the procedure explained in [1].\n",
    "\n",
    "Please load the data from the file: *dataTP.npz* where *T1x* is a matrix containing the averaged density (each row is a subject and each column a feature), *y* is a vector containing the diagnosis (0 for controls and 1 for Alzheimer’s patients) and *ROIlabelsx* contains the name of the ROI of each feature. Here, *x* can take the name of the three atlases you have at your disposal: AAL2, [AICHA](http://www.gin.cnrs.fr/fr/outils/aicha/), [HAMMERS](https://brain-development.org/brain-atlases/adult-brain-atlases/).\n",
    "\n",
    "**Reference**:\n",
    "[1] J. Samper-González, N. Burgos, S. Bottani, S. Fontanella, P. Lu, A. Marcoux, A. Routier, J. Guillon, M. Bacci, J. Wen, A. Bertrand, H. Bertin, M.-O. Habert, S. Durrleman, T. Evgeniou, O. Colliot. *Reproducible evaluation of classification methods in Alzheimer's disease: framework and application to MRI and PET data*. NeuroImage, 2018 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "cdBPjnmyo1_k",
    "outputId": "61bd3501-cbd7-46c3-a0b7-f313da98cfc7"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=ImportWarning)\n",
    "\n",
    "# Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install -q nilearn\n",
    "from nilearn import plotting\n",
    "%matplotlib inline\n",
    "np.random.seed(seed=666)\n",
    "\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "gdd.download_file_from_google_drive(file_id='11cQmPm64k3T7ml5fPLetZgb1j1AjHBH8',\n",
    "dest_path='./dataTP.npz')\n",
    "gdd.download_file_from_google_drive(file_id='1S7e5IrPygE4VV0JTwqJIlyO2S_NhsiI4',\n",
    "dest_path='./AtlasAAL2.nii')\n",
    "gdd.download_file_from_google_drive(file_id='1E0pu5jIMpgcs2DQ8lBGWliwEBZvKrnV9',\n",
    "dest_path='./AtlasAICHA.nii')\n",
    "gdd.download_file_from_google_drive(file_id='1yltKwULrkHYh79RAh_zAg08r8pQMjRlQ',\n",
    "dest_path='./AtlasHAMMERS.nii')\n",
    "\n",
    "with np.load('./dataTP.npz',allow_pickle=True) as data:\n",
    "    T1AAL2 = data['T1AAL2'] # data from AAL2 Atlas\n",
    "    T1AICHA = data['T1AICHA'] # data from AICHA Atlas\n",
    "    T1HAMMERS = data['T1HAMMERS'] # data from HAMMERS Atlas  \n",
    "    y = data['y'] # classes, 0 for controls and 1 for patients    \n",
    "    ROIlabelsAAL2 = data['ROIlabelsAAL2'] # labels for ROIs of atlas AAL2 \n",
    "    ROIlabelsAICHA = data['ROIlabelsAICHA']    # labels for ROIs of atlas AICHA \n",
    "    ROIlabelsHAMMERS = data['ROIlabelsHAMMERS']    # labels for ROIs of atlas HAMMERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "G-kuwBwFIilJ",
    "outputId": "81a647dd-6530-487a-cb0b-162f12c77ded"
   },
   "outputs": [],
   "source": [
    "# Choose Atlas (here AAL2)\n",
    "X=T1AAL2\n",
    "labels=ROIlabelsAAL2\n",
    "atlas='./AtlasAAL2.nii'\n",
    "\n",
    "N,M = X.shape # number subjects and ROIs\n",
    "class_names = [\"control\",\"alzheimer\"] # y=0, y=1\n",
    "\n",
    "print('Number of controls and Alzheimer patients is respectively: {0} and {1}'.format(N-np.sum(y), np.sum(y)))\n",
    "print('Number of ROI is: {0}'.format(M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Pk4GnWxo1_7"
   },
   "source": [
    "Using the library nilearn we can also plot the atlas used to define the ROIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "5LUtw8L2o1_-",
    "outputId": "8d0e8c2d-151d-4e0f-b263-463e36da66ea"
   },
   "outputs": [],
   "source": [
    "plotting.plot_roi(atlas, title=\"AAL2 atlas\")\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FIMJctdo2AE"
   },
   "source": [
    "In this TP we will use Decision Trees, Bagging and Random Forests. Let's start with Decision Trees. First of all, we need to scale the features so that each feature will have average equal to 0 and unit variance and create a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5LgMdc3xo2AK"
   },
   "outputs": [],
   "source": [
    "XXXXXXXXXXXX\n",
    "\n",
    "# Create training and test set\n",
    "X_train, X_test, y_train, y_test = XXXXXXXXXXXX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1HN5Uy2o2AO"
   },
   "source": [
    "Then, we can fit a Decision tree, with the default setting, using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aTe1dj0No2AP"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Fitting Decision Trees with maximum depth equal to 4 (to keep the output simple)\n",
    "Tree = DecisionTreeClassifier(max_depth=4)\n",
    "Tree.fit(X_train,y_train)\n",
    "# Score in the training set\n",
    "print('Score in the training set is {0}'.format(Tree.score(X_train,y_train)) )\n",
    "# Score in the test set\n",
    "print('Score in the test set is {0}'.format(Tree.score(X_test,y_test)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j5HzkZCPo2Ab"
   },
   "source": [
    "Instead than using the default hyperparameters, we could also look for the best ones. Among the hyperparameters implemented in *scikit-learn* we could use *'min_samples_split'*, the minimum number of samples required to split an internal node, and/or *'min_samples_leaf'*, the minimum number of samples required to be present at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. \n",
    "\n",
    "Plot the training and test score for different values of 'min_samples_split' (for instance between 1 and 10) WITHOUT using Cross Validation. Do the same for 'min_samples_leaf'. **Question:** What is the best value ? What happens if you split differently your data ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tKVCOi5oo2Ac"
   },
   "outputs": [],
   "source": [
    "# 'min_samples_split'\n",
    "TTest=[]\n",
    "TTrain=[]\n",
    "XXXXXXXXXXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCR-8VVpQpsN"
   },
   "outputs": [],
   "source": [
    "# 'min_samples_leaf'\n",
    "TTest=[]\n",
    "TTrain=[]\n",
    "XXXXXXXXXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yI1gFa97o2Ao"
   },
   "source": [
    "Try to add Gaussian noise to the data (using for instance zero mean and 0.5 for the std) and, using the best hyperparameters found before, look at the test score. Repeat this process several times (at least 100 times) and compare the results with the score obtained without adding noise. **Question:** Are the results stable ? Hint: you could use for instance *noise = np.random.normal(mu, sigma)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rppiIbQFo2Ap"
   },
   "outputs": [],
   "source": [
    "XXXXXXXXXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RrLs1nn8o2AU"
   },
   "source": [
    "To plot decision trees, we can also use the *graphviz* library. If you need to install it locally, you can do it using *conda install python-graphviz*. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkOG-YOvks1E"
   },
   "source": [
    "First plot the tree learnt on the original data, witout adding noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2fXiMYIo2AW"
   },
   "outputs": [],
   "source": [
    "import graphviz \n",
    "\n",
    "Tree.fit(X_train,y_train)\n",
    "dot_data = tree.export_graphviz(Tree, out_file=None,feature_names=labels,class_names=class_names,filled=True, rounded=True,special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jPDvOh79mcrj"
   },
   "source": [
    "Now, plot the tree learnt on noisy data. **Question:** Is it the same ? You can try several times, for different levels of noise. Comment the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ovWKd3PUlwh6"
   },
   "outputs": [],
   "source": [
    "XXXXXXXXXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RLQwNNCco2At"
   },
   "source": [
    "Instead than using a single split of the data, we could also use Cross Validation to compute the best hyperparameter values for both 'min_samples_split' and 'min_samples_leaf' at the same time and in an automatic way. **Question:** Do you find the same optimal hyperparameters as before ? Hint: use GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zDvf_RYTo2Av"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "XXXXXXXXXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JC7SNh5-o2A2"
   },
   "source": [
    "Using the optimal hyperparameers, plot again the decision tree using the *graphviz* library. **Question:** Is it the same ? Do you see ROIs that are always present nearby the root of the trees ? Comment the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-5ucpzowo2A4"
   },
   "outputs": [],
   "source": [
    "XXXXXXXXXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tK17gOu9o2A9"
   },
   "source": [
    "Try to use now Bagging. You can use the following code where we use the previously computed best parameters 'min_samples_leaf' and 'min_samples_split'. **Question:** What happens when you use the original data and the noisy version ? Do you notice any difference in the prediction scores with respect to the results using Decision Trees ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ij465Vaho2A-"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "Tree = DecisionTreeClassifier(criterion=\"gini\",min_samples_leaf=XXXXXXXXXXXX,min_samples_split=XXXXXXXXXXXX, random_state=0)\n",
    "\n",
    "p_grid_bagging = {'n_estimators': [5,10,15,20]}      \n",
    "bag=BaggingClassifier(base_estimator=Tree, random_state=0)\n",
    "grid_bagging = GridSearchCV(estimator=bag, param_grid=p_grid_bagging, scoring=\"accuracy\", cv=5)\n",
    "grid_bagging.fit(X_train, y_train)\n",
    "print(\"Best Score: {}\".format(grid_bagging.best_score_))\n",
    "print(\"Best params: {}\".format(grid_bagging.best_params_))\n",
    "print(\"Bagging score :\",grid_bagging.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "91OSfGQwo2BC"
   },
   "outputs": [],
   "source": [
    "XXXXXXXXXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STHcxeyfo2BF"
   },
   "source": [
    "The last part of this TP is about Random Forests. We can estimate the three hyperparameters *'n_estimators'*, *'min_samples_leaf'* and *'max_features'*, the number of features to consider when looking for the best split, as before using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6BE-H8ywo2BG"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF=RandomForestClassifier(criterion=\"gini\", random_state=0)\n",
    "p_grid_RF = {'n_estimators': [10,15,20,25,30], 'min_samples_leaf': [2,3,4,5,6], 'max_features': ['sqrt','log2']}   \n",
    "\n",
    "grid_RF = GridSearchCV(estimator=RF, param_grid=p_grid_RF, scoring=\"accuracy\", cv=5)\n",
    "grid_RF.fit(X_train, y_train)\n",
    "print(\"Best Score: {}\".format(grid_RF.best_score_))\n",
    "print(\"Best params: {}\".format(grid_RF.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iI414cecG3i3"
   },
   "source": [
    "**Question:** Using the estimated best hyperparameters, test the performance of Random Forest on the noisy data and compare the results with Decision Trees and Bagging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MnwoUhr3G6b1"
   },
   "outputs": [],
   "source": [
    "XXXXXXXXXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GbPiUrNAo2BN"
   },
   "source": [
    "We can also use Random Forests to check the importance of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N7PU3C8ko2BQ"
   },
   "outputs": [],
   "source": [
    "best_params=grid_RF.best_params_\n",
    "RF = RandomForestClassifier(criterion=\"gini\",min_samples_leaf=best_params[\"min_samples_leaf\"],max_features=best_params[\"max_features\"],n_estimators=best_params[\"n_estimators\"], random_state=0)\n",
    "RF.fit(X_train,y_train)\n",
    "\n",
    "importances = RF.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(10):\n",
    "    print(\"%d. feature %d representing %s (%f)\" % (f + 1, indices[f], labels[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importance\")\n",
    "plt.bar(range(10), importances[indices[0:10]], color=\"r\", align=\"center\")\n",
    "plt.xticks(range(10), indices[0:10])\n",
    "plt.xlim([-1, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uiNUODxOo2BU"
   },
   "source": [
    "**Question:** Which are the most important features (i.e. ROIs) ?  Based on the two given research papers, you can verify if your results make sense. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "psuqzjU5o2BY"
   },
   "source": [
    "We can also inspect the data using only pairs of the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "om2OxZ3bo2Bb"
   },
   "outputs": [],
   "source": [
    "for pairidx, pair in enumerate([ [indices[0],indices[1]], [indices[0],indices[2]], [indices[0],indices[3]],\n",
    "                                [indices[1],indices[2]], [indices[1],indices[3]], [indices[2],indices[3]] ]):\n",
    "    # We only take the two corresponding features\n",
    "    Xpair = X_train[:, pair]\n",
    "    ypair = y_train\n",
    "\n",
    "    # Train\n",
    "    clf = RF.fit(Xpair, ypair)\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    plt.subplot(2, 3, pairidx + 1)\n",
    "\n",
    "    x_min, x_max = Xpair[:, 0].min() - 1, Xpair[:, 0].max() + 1\n",
    "    y_min, y_max = Xpair[:, 1].min() - 1, Xpair[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "    plt.xlabel(pair[0])\n",
    "    plt.ylabel(pair[1])\n",
    "\n",
    "    # Plot the training points\n",
    "    for i, color in zip(range(2), \"yk\"):\n",
    "        idx = np.where(ypair == i)\n",
    "        plt.scatter(Xpair[idx, 0], Xpair[idx, 1], c=color, label=class_names[i],\n",
    "                    cmap=plt.cm.RdYlBu, edgecolor='black', s=15)\n",
    "\n",
    "plt.suptitle(\"Decision surface of a random forest using couples of the most important features\")\n",
    "plt.legend(bbox_to_anchor=(1, 0.5))\n",
    "plt.axis(\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OJMWJrFh0mGO"
   },
   "source": [
    "**Question:** Which is the best couple of features ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZjHYuz7sAIU"
   },
   "source": [
    "**Different Atlas**\n",
    "\n",
    "Previously, we have used the AAL2 which defines a precise split of the brain into ROIs.\n",
    "**Question:** What happens if you change Atlas ? Do you obtain the same results ? Can you find a subset of ROIs that you could define 'biomarkers' of the Alzheimer's disease ? Justify your answer and check whether it makes sense by using the two given research papers.\n",
    "\n",
    "You can use the AICHA (http://www.gin.cnrs.fr/fr/outils/aicha/) and HAMMERS (https://brain-development.org/brain-atlases/adult-brain-atlases/) atlas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvOzYaqdruLs"
   },
   "source": [
    "**Theoretical Questions**\n",
    "\n",
    "**Question:** Please answer the two questions at slide 28 and 31 writing here the computations."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TP_Trees.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
